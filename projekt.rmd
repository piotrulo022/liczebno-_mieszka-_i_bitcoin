---
title: "Analiza zmiany liczebności mieszkań oddanych do użytku i notowań kryptowaluty Bitcoin."
subtitle: "Inżynieria i Analiza Danych 2022/23"
author: "Piotr Szyszka, Weronika Nadworska"
date: "31-01-2023"
output: 
  pdf_document:
    toc: true
toc-title: Spis treści
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```


```{r biblioteki, include = FALSE}
library(tidyverse)
library(tseries)
library(lmtest)
library(forecast)
library(flextable)
library(kableExtra)
```

\pagebreak

# Słowem wstępu

Dokument jest wynikiem pracy nad projektem zaliczeniowym na przedmiot *Szeregi czasowe*.

Głównym celem raportu jest opis i identyfikacja zjawisk wymienionych w tytule za pomocą metod poznanych na przedmiocie.

Przeprowadzona analiza pozwoli na lepsze zrozumienie charakteru opisywanych cech, co może być cenne z ekonomicznego punktu widzenia.

# Mieszkania, których budowę rozpoczęto

Pierwszym zjawiskiem, które zostało przez nas zbadane to zmiana liczebności mieszkań, których budowę rozpoczęto w latach 2005-2021. 
Dane umożliwiają bieżącą oraz roczną ocenę aktywności produkcyjnej przemysłu. W zakresie budownictwa prezentowane dane charakteryzują etapy procesu budowlanego w zakresie: wydanych pozwoleń na budowę, mieszkań, których budowę rozpoczęto, budynków (mieszkalnych i niemieszkalnych) i mieszkań oddanych do użytkowania oraz sprzedaży sekcji F Budownictwo, w tym produkcji budowlano-montażowej zrealizowanej przez przedsiębiorstwa budowlane.

 [Źródło](https://bdl.stat.gov.pl/ "Bank Danych Lokalnych GUS") 

```{r, include = FALSE}
dane <- read.csv(file = "mieszkania_rozpoczeto_ogolem.csv", sep = ';', header = TRUE, na.strings = c("NA", "<NA>"))
mieszkania <- t(dane)
colnames(mieszkania) <- mieszkania[2, ]

mieszkania <- mieszkania[-(1:2), ] 
mieszkania <- as.data.frame(mieszkania)
mieszkania <- na.omit(mieszkania)
mieszkania$LUBELSKIE <- as.numeric(mieszkania$LUBELSKIE)
mieszkania$`Powiat lubelski` <- as.numeric(mieszkania$`Powiat lubelski`)
mieszkania$`Powiat m.Lublin` <- as.numeric(mieszkania$`Powiat m.Lublin`)

szeregowanie <- function(x){
  tmp <- NULL
  miesiace <- NULL

# k - miesiace
# i - lata 
for(k in 1:11){
  tmp <- NULL
    for(i in 1:17){
    tmp <- c(tmp, x[k*17+i] - x[(k-1)*17+i])
    }
  miesiace[[k]] <- tmp
}

pom <- data.frame(miesiace)
pom <- cbind(x[1:17], pom)
szereg <- as.numeric(matrix(t(pom)))
return (szereg) # voile-la
}

lubelskie <- szeregowanie(mieszkania$LUBELSKIE)
```

```{r}
mies <- c("styczeń", "luty", "marzec", "kwiecień", "maj", "czerwiec", "lipiec", "sierpień", "wrzesień", "październik", "listopad", "grudzień")
lata <- NULL
for(i in 1:17){
lata <- c(lata, rep(2004+i, 12))
}

ramka <- as.data.frame(lubelskie)
rownames(ramka) <- paste(mies, lata)

ramka %>% 
  head(12) %>% 
  rownames_to_column(var="    ") |> 
  flextable()
```

\newpage

## Scharakteryzowanie danych


```{r staty}
as.data.frame(rbind(apply(ramka, 2, summary), Sd = apply(ramka, 2, sd))) %>% round() %>% rownames_to_column(var = "Statystyka") %>% flextable()
```

Z zestawienia widzimy, że najmniejsza liczba budów, których budowę rozpoczęto to 58 (luty 2005). Najwięcej (2086) rozpoczęto budować w marcu 2021.

```{r out.width="60%", out.height="95%", fig.align='center'}
plot(lubelskie, col=4, main="Liczby mieszkań w latach 2005-2021, których budowę rozpoczęto", type="l", xlab = "czas (miesiące)", ylab = "liczba")
```

Wyraźnie dostrzegalna jest sezonowość (coroczna, o charakterze addytywnym) wraz z pewnymi wahaniami losowymi. 

```{r out.width="60%", out.height="95%", fig.align='center'}
hist(lubelskie, breaks = 15, col=4, main="Histogram liczby nowych mieszkań",
     xlab="Liczba mieszkań", ylab="Prawdopodobieństwo", prob=T)

gestosc <- density(lubelskie)
lines(x=gestosc$x, y=gestosc$y, col="#FF2400", lwd=2)
```

Rozkład cechuje się prawostronną asymetrią.

```{r out.width="60%", out.height="95%", fig.align='center'}
boxplot(lubelskie, col="#007FFF", main="Wykres ramka-wąsy")
```

## Funkcja autokorelacji

Szeregi czasowe charakteryzują się tym, że kolejne elementy w większości przypadków nie są niezależne.  \newline
Miarą zależności pomiędzy elementami stacjonarnego szeregu czasowego są współczynniki korelacji, które nazywane są również funkcją autokorelacji (*ang. ACF - Auto-Correlation Function*). Wyrażona jest ona wzorem: 

$$
r_{\tau} = \frac{E(x_t - \mu)(x_{\tau +r} - \mu)}{E(x_{t+\tau} - \mu)^2} = \frac{\gamma_r}{\gamma_0}
$$

A za estymator przyjmuje się

$$
\hat{r}_\tau = \frac{N \sum_{t = 1}^{N - \tau}(x_t - \hat{\mu})(x_{t+\tau} - \hat{\mu})}{(N-\tau)\sum_{t = 1}^{N}(x_t - \hat{\mu})^2} = \frac{\hat{\gamma}_\tau}{\hat{\gamma}_0}
$$
gdzie $\tau = 0, 1, ..., N-1$ jest przesunięciem (opóźnieniem). 

W `R` funkcja autokorelacji zaimplementowana jest pod nazwą `Acf()` z pakietu `forecast`. Użycie jej skutkuje wywołaniem wykresu $r_\tau$ w zależności od $\tau$ zwanej **korelogramem.**

```{r out.width="60%", out.height="95%", fig.align='center'}
szereg <- ts(lubelskie, frequency = 12)
par(mfrow = c(2, 2))
Acf(x = szereg, lag.max = 1, type = "correlation")
Acf(x = szereg, lag.max = 10, type = "correlation")
Acf(x = szereg, lag.max = 25, type = "correlation")
Acf(x = szereg, lag.max = 50, type = "correlation")
par(mfrow = c(1,1))
```

Wykresy przedstawiają funkcję autokorelacji odpowiednio dla $\tau = 1$, $\tau = 10$, $\tau = 25$ oraz $\tau = 50$.

## Dekompozycja i wygładzanie metodą Holt'a Winters'a

### Dekompozycja

Funkcja `decompose()` z bazowej biblioteki `stats` umożliwia dekompozycję szeregu na trzy główne składowe, tj. trend, sezonowość i wahania losowe.

```{r out.width="60%", out.height="95%", fig.align='center'}
dek <- decompose(szereg)
plot(dek)
```

### Metoda Holt'a Winters'a

Model *Holt'a-Winters'a* jest jedną z technik prognozowania wykorzystujących tzw. wygładzenie wykładnicze. Wygładzenie polega na stworzeniu ważonej średniej ruchomej, której wagi określa się według schematu - im starsza informacja o badanym zjawisku, tym mniejszą wartość stanowi ona dla aktualnej prognozy. 

Możemy wyróżnić trzy rodzaje modeli Holta-Wintersa:

- bez sezonowości,

- z sezonowością multiplikatywną,

- z sezonowością addytywną.

W naszym przypadku (sezonowość addytywna) \textit{Holt'a - Winters'a} ma postać:

$$
  \hat{y}_{t+h|t} = \ell_t + hb_t + s_{t+h-m(k+1)}
$$

gdzie: k jest częścią całkowitą liczby $\frac{h-1}{m}$, $m$ - długość okresu, $h$ - przesunięcie czasowe. \newline
Dodatkowo

$$
\ell_t = \alpha(y_t - s_{t-m})+(1-\alpha)(\ell_{t-1}+b_{t-1})
$$
odpowiada za prognozę niesezonową.

$$
b_t = \beta(\ell_t - \ell_{t-1})+(1-\beta)b_{t-1}
$$
$b_t$ jest czynnikiem odpowiedzialnym za trend, a


$$
  s_t = \gamma(y_t - \ell_{t-1} - b_{t-1}) + (1-\gamma)s_{t-m}
$$
jest sezonowym składnikiem szeregu czasowego o okresie $m$


### Dopasowanie 

Model *Holt'a-Winters'a* można utworzyć za pomocą funkcji `HoltWinters()` dostępnej w bazowej bibliotece `stats`.

```{r out.width="60%", out.height="95%", fig.align='center'}
hw <- HoltWinters(szereg)
plot(hw, lwd = 2.2)
legend(x = 3, y = 2000, legend = c("Empiryczne","Holta-Wintersa"), lty = "solid", col = c("black", "red"))
```


### Predykcja

Predykcja na kolejne 10 notowań prezentuje się następująco:

```{r}
predict(hw, n.ahead = 10)
```


## Trendy fazowe


```{r, out.width="70%", out.height="60%", fig.align='center'}
momenty <- (1:17)*12
par(mfrow = c(4, 4))
par(mar = rep(2, 4))
op <- par(oma=c(5,7,1,1))
par(op)
for(j in 1:16){
  pom <- lubelskie[(j:j+momenty)]
  t <- 1:length(pom)
  mdl <- lm(pom ~ t)
  plot(pom, type = "l", col = "steelblue", xlab = "notowania")
  title(sprintf("Wykres dla fazy %i", j))
  
  lines(mdl$fitted.values, type = "l", col = "red")
}
par(mfrow = c(1,1))
```


## Dopasowanie trendu wielomianem

W celu ułatwienia zadania przypomnijmy sobie jakiej postaci jest trend.

```{r out.width="60%", out.height="95%", fig.align='center'}
plot(dek$trend)
```

Korzystając z wygód, jakie oferuje oprogramowanie RStudio, do znalezienia odpowiedniego stopnia dopasowania wielomianem, napiszemy funkcję. Za kryterium przyjmiemy najniższą wartość indeksu ***AIC***.

```{r, echo = TRUE, out.width="60%", out.height="95%", fig.align='center'}
fit <- function(szereg, max.st){
  aic <- modele <- NULL
  t <- 1:length(szereg)
  for(i in 1:max.st){
   mod <- lm(szereg ~ poly(t, i))
   aic <- c(aic, AIC(mod))
   modele[[i]] <- mod
  }
  opt <- which(aic == min(aic))
  par(mfrow = c(1, 2))
  plot(aic, type = "b")
  plot(x = szereg, type = "l", col = "steelblue")
  lines(modele[[opt]]$fitted.values, type = "l", col = "red")
  title(sprintf("Dopasowanie wielom. st. %i.", opt))
  par(mfrow = c(1,1))
  cat("Najlepsze AIC = ", aic[opt], sprintf("dla wielomianu %i", opt), "stopnia.")
  modele[[opt]]
}
```

Poszukiwania stopnia wielomianu zawężmy do 15-tej potęgi.

```{r trend, results='asis',out.width="60%", out.height="95%", fig.align='center'}
trend <- as.numeric(dek$trend)
mod <- fit(na.omit(trend), max.st = 15)
```

Najlepszy pod względem dopasowania okazał się wielomian stopnia 12. Wartość *AIC* dla tego dopasowania wynosi 1789.

## Stacjonarność

Szereg $\{x_t\}_{1 \leq t \leq N}$ nazywamy ściśe stacjonarnym, jeżeli dla dowolnych $m, t_1, t_2, ..., t_m, \tau$ łączny rozkład prawdopodobieństwa związany z $m$ elementami $x_{t_1},x_{t_2},..., x_{t_m}$ szeregu czasowego jest identyczny z rozkładem $m$ elementów.

Innymi słowy, szereg jest stacjonarny jeśli jego własności dynamiczne nie ulegają zmianie przy zmianie początku skali czasowej.

Zbadamy stacjonarność szeregu. Posłużą do tego testy Kwiatkowskiego-Phillips'a-Schmidt'a-Shin'a oraz Dicky'ego-Fullera.

```{r}
kpss.test(szereg) # nie jest stacjonarny
kpss.test(diff(szereg)) # jest stacjonarny po zroznicowaniu
adf.test(diff(szereg)) # jest stacjonarny
```

Badajac stacjonarność szeregu testem KPSS wyciagamy wniosek o niestacjonarności badanego szeregu. Jednak po jednokrotnym zróżnicowaniu szereg jest stacjonarny.

## SARIMA

Model klasy \textit{SARIMA} (ang. \textit{Seasonal AutoRegressive Integrated Moving Average}) rozszerzeniem modelu ARIMA o czynnik sezonowy. 
Parametry modelu \textbf{ARIMA(p, d, q)} 

- p - parametr autoregresyjny; rząd opóźnienia,

- d - parametr różnicowania (ilość potrzebnych zróżnicowań, aby szereg stał się stacjonarny)

- q - parametr średniej ruchomej.

\textit{SARIMA(p, d, q, P, D, Q)} jest wzbogacona o dodatkowe trzy parametry, które oznaczają dokładnie to co w modelu \textit{ARIMA}, ale dotyczą składowej sezonowości szeregu. Stąd model można przedstawić w postaci

$$
  y_t = c + \sum_{n = 1}^p \alpha_ny_{t-n} + \sum_{n = 1}^q \theta_n\epsilon_{t-n} + \sum_{n = 1}^P \phi_n y_{t-sn} + \sum_{n = 1}^P \eta_n \epsilon_{t-sn}  + \varepsilon_t
$$

```{r out.width="85%", out.height="95%", fig.align='center'}
# model SARIMA i prognoza
sarima <- auto.arima(szereg, seasonal = TRUE)

plot(szereg, col = "steelblue", xlab="czas(miesiące)", ylab="")
lines(sarima$fitted, col = "red")
legend(x = 2, y = 2000, legend = c("Empiryczne", "SARIMA(2,0,3,0,0,2)"), 
       col = c("steelblue", "red"), lty = "solid")
```


Wyznaczymy przedziały ufności na kolejne 12 notowań.


Dla $\alpha=0,05$:

```{r}
forecast(sarima, h = 12, level = 0.95)
```

Dla $\alpha=0,1$:

```{r}
forecast(sarima, h = 12, level = 0.9)
```

### Identyfikacja rezt 

Zajmiemy się teraz analizą szeregu reszt powstałego modelu. Prezentują sie one następująco:

```{r out.width="60%", out.height="95%", fig.align='center'}
# identyfikacja reszt
sar_res <- sarima$residuals
plot(sar_res, xlab="czas (miesiące)", ylab="", col = "steelblue")
title("Wykres reszt")
```


```{r out.width="60%", out.height="95%", fig.align='center'}
hist(sar_res, main="Histogram reszt", xlab="reszty", ylab="")
```

Zauważyć można prawostronną asymetrię rozkładu.

Przeprowadzimy teraz testy sprawdzające normalność, jednorodność wariancji oraz seryjną korelację błędów modelu SARIMA.

Normalność:

```{r out.width="60%", out.height="95%", fig.align='center'}
qqnorm(sar_res)
qqline(sar_res)
shapiro.test(sar_res)
nortest::ad.test(sar_res)
nortest::lillie.test(sar_res)
```

Odrzucamy hipotezę o normalności rozkładu reszt w modelu.

Jednorodność wariancji:

```{r}
t <- 1:204
bptest(as.numeric(sar_res)~t)
gqtest(sar_res~t)
hmctest(sar_res~t)
```

Na podstawie testów Breucha-Pagana, Goldfelda-Quandta oraz Harrisona-McCabe'a odrzucamy hipotezę o jednorodności wariancji błędów.

Seryjna korelacja:

```{r}
dwtest(sar_res~t)
bgtest(sar_res~t, order = 3)
```

Na podstawie testów Durbina-Watsona oraz Breucha-Godfreya nie ma podstaw do odrzucenia hipotezy o braku seryjnej korelacji między błędami modelu.

## Podsumowanie

W ostatnich okresach coraz bardziej dostrzegalna staje się tendencja wzrostowa liczby mieszkań, których budowę rozpoczęto, przez co szeregu nie można określić jako stacjonarny. Świadczyć może to o rozwoju tego sektora gospodarki.\newline
Zjawisko cechuje się sezonowością, którego dopasowanie modelem \textit{SARIMA} oceneniamy na przyzwoite, podobnie jak wygładzenie metodą \textit{Holt'a-Winters'a}.\newline
W przeciwieństwie do badanego procesu, jego składowe takie jak trend oraz trendy fazowe, precyzyjnie identyfikować można za pomocą modeli regresji wielomianowej.


# Bitcoin

Bitcoin to otwartoźródłowa, zdecentralizowana platforma płatnicza, która jest zbudowana w oparciu o technologię blockchain (łańcucha bloków) i wykorzystuje własną kryptowalutę o tej samej nazwie (oznacza się ją symbolem BTC).\newline
Kryptowaluta bitcoin została wprowadzona w 2009 roku przez osobę, bądź grupę osób o pseudonimie Satoshi Nakamoto.\newline
Dane na temat notowań zostały pozyskane z [yahoo finance](https://finance.yahoo.com/) i dotyczą okresu całego poprzedniego roku od dnia 24.01.2022 roku.

```{r}
btc <- get.hist.quote(instrument = "BTC-USD",
                      start = "2022-01-24",
                      end = "2023-01-24",
                      quote = "Close")
btc <- na.omit(btc)
btc %>% head(18) %>% as.data.frame() %>% rownames_to_column(var = "   ") %>% flextable()
```

Ceny waluty bitcoin wyrażone są w dolarach amerykańskich.


## Scharakteryzowanie danych

```{r}
rbind(apply(btc, 2, summary), Sd. = apply(btc, 2, sd)) %>% as.data.frame() %>% rownames_to_column(var = "   ") %>% flextable()
```

Widzimy, że średnia cena bitcoin wynosi 26 730,36 $\$$. Minimalna wartość to 15 787,28 $\$$.

```{r out.width="60%", out.height="95%", fig.align='center'}
plot(btc, col = "steelblue", main="Notowania cen bitcoin w czasie 24.01.2022-24.01.2023")
```

Zauważyć można spory spadek cen cyfrowej waluty od kwietna do końca czerwca, po czym nastąpiła stabilizacja.

```{r out.width="60%", out.height="25%", fig.align='center'}
boxplot(btc, col = "green", main = "Wykres ramka-wąsy")
```


```{r out.width="60%", out.height="95%", fig.align='center'}
hist(btc, col = "lightgreen", prob = T, breaks=10, main = "Histogram cen bitcoin")
gestosc <- density(btc)
lines(x=gestosc$x, y=gestosc$y, col="red", lwd=2)
```

Zauważalna jest dwumodalność rozkładu.

## Funkcja autokorelacji

Użyjemy funkcji autokorelacji `Acf()` zaimplementowanej w programie RStudio w pakiecie `forecast`. Użycie jej skutkuje wywołaniem wykresu $r_\tau$ w zależności od $\tau$.

```{r out.width="60%", out.height="95%", fig.align='center'}
bitcoin <- ts(btc, frequency = 31) # ??????
par(mfrow = c(2, 2))
acf(bitcoin, lag = 10)
acf(bitcoin, lag = 25)
acf(bitcoin, lag = 50)
acf(bitcoin, lag = 75)
par(mfrow = c(1,1))
```

Wykresy przedstawiają funkcję autokorelacji odpowiednio dla $\tau = 10$, $\tau = 25$, $\tau = 50$ oraz $\tau = 75$.


## Wygładzanie Holt'a-Winters'a

Zwizualizujemy najpierw dekompozycję badanego szeregu na trzy główne składowe: trend, sezonowość i wahania losowe.

```{r out.width="60%", out.height="95%", fig.align='center'}
dek_btc <- decompose(bitcoin)
plot(dek_btc)
```

\newpage

Zbudujemy model *Holt'a-Winters'a*, ponownie, korzystajac z funkcji `HoltWinters()` dostępnej w bazowej bibliotece `stats`.

```{r out.width="60%", out.height="95%", fig.align='center'}
hw <- HoltWinters(bitcoin)
plot(hw)
legend(x = 8, y = 50000, legend = c("Holt'a-Winters'a", "Empiryczne"), 
       lty = "solid",
       col = c("red", "black"))
```

## Predykcja

Dokonamy predykcji na kolejne 10 notowań:

```{r}
predict(hw, n.ahead = 10)
```


## Regresja wielomianowa

Dopasujmy cechę oraz trend występujący w szeregu korzystając z regresji wielomianowej. 

\newpage

### Dopasowanie trendu

Przypomnijmy sobie najpierw jakiej postaci jest trend.

```{r out.width="60%", out.height="95%", fig.align='center'}
plot(dek_btc$trend)
```

Dopasowując wielomian odpowiedniego stopnia ponownie posłużymy się zbudowaną przez nas wcześniej funkcją `fit()`.
 

Zawęźmy poszukiwania do stopnia 20.

```{r out.width="60%", out.height="95%", fig.align='center'}

trend_btc <- dek_btc$trend
tr <- fit(as.numeric(trend_btc), max.st = 15)
```

Najlepsze okazało się dopasowanie wielomianem stopnia piętnastego, dla którego kryterium *AIC* wynosi 4940.

\newpage

### Dopasowanie cechy

Poszukajmy wielomianu stopnia maksymalnie piętnastego.

```{r out.width="60%", out.height="95%", fig.align='center'}
modbtc <- fit(btc, max.st = 15)
```

Wielomian stopnia piętnastego okazał się najlepiej dopasowany do badanej cechy. Kryterium *AIC* wynosi dla niego 6452.

### Analiza szeregu reszt modelu regresji wielomianowej

Wykresy modelu reszt prezentują się następująco:

```{r out.width="75%", out.height="120%", fig.align='center'}
library(ggfortify)
autoplot(modbtc)
reszty2 <- modbtc$residuals
```

Zbadamy teraz jednorodność wariancji rozkładu błędów szeregu reszt. Posłużą nam do tego testy Goldfelda-Quandta oraz Harrisona-McCabe'a.

```{r}
gqtest(modbtc) 
hmctest(modbtc)
```

Nie ma podstaw do odrzucenia $H_0$ o jednorodności wariancji błędów.

Seryjną korelację błędów zbadamy korzystając z testów Durbina-Watsona oraz Breucha-Godfreya.

```{r}
dwtest(modbtc) # sa zalezne
bgtest(modbtc) # sa zalezne
```

Na podstawie przeprowadzonych testów odrzucamy hipotezę o braku autokorelacji między błędami.

Zbadamy teraz normalność szeregu reszt.

```{r}
shapiro.test(as.numeric(reszty2))
```

Odrzucamy hipotezę o normalności rozkładu błędów.

\newpage

## Stacjonarność

Zbadamy stacjonarność szeregu. Posłużą do tego testy Kwiatkowskiego-Phillips'a-Schmidt'a-Shin'a oraz Dicky'ego-Fullera.

```{r}
kpss.test(bitcoin) # nie jest stacjonarny
kpss.test(diff(bitcoin)) # jest stacjonarny po zroznicowaniu
adf.test(diff(bitcoin)) # jest stacjonarny
```

Szereg jest niestacjonarny, ale po jednokrotnym zróżnicowaniu wnioskujemy o jego stacjonarności.

## ARIMA

Skorzystamy z modelu klasy ARIMA.

```{r}
arim <- auto.arima(bitcoin, seasonal = F)
```


```{r out.width="60%", out.height="95%", fig.align='center'}
plot(bitcoin)
lines(arim$fitted, col=2)
legend(x=9, y=43000, legend = c("Empiryczne", "ARIMA(0,1,0)"), col = c(1,2), lty="solid")
```



Optymalne wartości kryteriów informacyjnych *AIC*, *AICc* oraz *BIC* uzyskaliśmy dla modelu ARIMA(0,1,0).


\newpage 
Zbudujemy teraz przedziały ufności na kolejne 10 notowań dla $\alpha=0,05$ oraz $\alpha=0,1$.

Dla $\alpha=0,05$:

```{r}
forecast(arim, h=10, level = 0.95)
```

Dla $\alpha=0,1$:

```{r}
forecast(arim, h=10, level = 0.9)
```

### Identyfikacja reszt

Zajmiemy się teraz analizą szeregu reszt w modelu. Prezentują sie one następująco:

```{r out.width="60%", out.height="95%", fig.align='center'}
# identyfikacja reszt
ari_res <- arim$residuals
plot(ari_res, xlab="czas (miesiące)", ylab="")
title("Wykres reszt")
```


```{r out.width="60%", out.height="95%", fig.align='center'}
hist(ari_res, main="Histogram reszt", xlab="reszty", ylab="")
```


Przeprowadzimy teraz testy sprawdzające normalność, jednorodność wariancji oraz seryjną korelację błędów modelu ARIMA.
Normalność:

```{r out.width="60%", out.height="95%", fig.align='center'}
qqnorm(ari_res)
qqline(ari_res)
shapiro.test(ari_res)
nortest::ad.test(ari_res)
nortest::lillie.test(ari_res)
```

Odrzucamy hipotezę o normalności rozkładu reszt w modelu.

Jednorodność wariancji:

```{r}
t <- 1:nrow(bitcoin)
gqtest(as.numeric(ari_res)~t)
hmctest(as.numeric(ari_res)~t)
```

Na podstawie testów Goldfelda-Quandta oraz Harrisona-McCabe'a na poziomie istotności 0,05 odrzucamy hipotezę o jednorodności wariancji błędów.

Seryjna korelacja:

```{r}
dwtest(ari_res~t)
bgtest(ari_res~t, order = 3)
```

Na podstawie testów Durbina-Watsona oraz Breucha-Godfreya nie ma podstaw do odrzucenia hipotezy o braku seryjnej korelacji między błędami modelu.

## Podsumowanie

Analizując wykres cen kryptowaluty zauważalny jest znaczący spadek w jej notowaniach, mający początek na początku drugiego kwartału ubiegłego roku, co spowodowane może być między innymi agresywną walką amerykańskiej \textit{Rezerwy Federalnej} z inflacją. \newline
W porównaniu z ubiegłym rokiem, na dzień dzisiejszy BITCOIN kosztuje dwa razy mniej. \newline
Model klasy \textit{ARIMA(0, 1, 0)} jest w stanie w dokładny sposób dopasować się do zgromadzonych danych, a wielomian stopnia 15. radzi sobie z tym dostatecznie dobrze. Wygładzanie \textit{Holt'a-Winters'a} również jest satysfakcjonujące, a występujący trend można modelować wielomianem stopnia piętnastego. \newline